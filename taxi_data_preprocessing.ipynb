{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e1ed6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (4.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.12/site-packages (from pyspark) (0.10.9.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a775bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b32dc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "INITIALIZING SPARK SESSION\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/24 18:22:36 WARN Utils: Your hostname, Kaweewat.local, resolves to a loopback address: 127.0.0.1; using 192.168.0.100 instead (on interface en0)\n",
      "25/11/24 18:22:36 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/24 18:22:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# SPARK SESSION INITIALIZATION\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"INITIALIZING SPARK SESSION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"TaxiDataProcessing\") \\\n",
    "    .config(\"spark.sql.adaptive.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.adaptive.coalescePartitions.enabled\", \"true\") \\\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.sql.parquet.mergeSchema\", \"true\") \\\n",
    "    .config(\"spark.sql.files.maxPartitionBytes\", \"128MB\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"WARN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90d27045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOADING DATA FROM DAILY PARQUET FILES WITH SAMPLING\n",
      "================================================================================\n",
      "\n",
      "Found 162 valid daily partitions (from 2021-01-01 onwards)\n",
      "Sample fraction: 10.0%\n",
      "Date range: 2021-08-04 to 2023-02-28\n",
      "\n",
      "[1/162] Processing: 2021-08-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[2/162] Processing: 2022-02-04\n",
      "   Records: 8\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[3/162] Processing: 2022-02-23\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[4/162] Processing: 2022-03-08\n",
      "   Records: 74\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 7 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[5/162] Processing: 2022-03-12\n",
      "   Records: 9\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[6/162] Processing: 2022-03-16\n",
      "   Records: 60\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 6 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[7/162] Processing: 2022-04-13\n",
      "   Records: 85\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 8 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[8/162] Processing: 2022-04-17\n",
      "   Records: 50\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 4 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[9/162] Processing: 2022-05-18\n",
      "   Records: 17\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 2 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[10/162] Processing: 2022-06-14\n",
      "   Records: 36\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 3 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[11/162] Processing: 2022-06-24\n",
      "   Records: 95\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 8 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[12/162] Processing: 2022-08-03\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[13/162] Processing: 2022-08-07\n",
      "   Records: 75\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 7 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[14/162] Processing: 2022-08-21\n",
      "   Records: 4\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[15/162] Processing: 2022-08-22\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[16/162] Processing: 2022-09-05\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[17/162] Processing: 2022-09-26\n",
      "   Records: 89\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 8 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[18/162] Processing: 2022-10-14\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[19/162] Processing: 2022-10-21\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[20/162] Processing: 2022-10-28\n",
      "   Records: 4\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[21/162] Processing: 2022-10-29\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[22/162] Processing: 2022-11-02\n",
      "   Records: 4\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[23/162] Processing: 2022-11-03\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[24/162] Processing: 2022-11-04\n",
      "   Records: 5\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[25/162] Processing: 2022-11-06\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[26/162] Processing: 2022-11-10\n",
      "   Records: 10\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[27/162] Processing: 2022-11-12\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[28/162] Processing: 2022-11-14\n",
      "   Records: 7\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[29/162] Processing: 2022-11-15\n",
      "   Records: 10\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[30/162] Processing: 2022-11-21\n",
      "   Records: 3\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[31/162] Processing: 2022-11-24\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[32/162] Processing: 2022-11-28\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[33/162] Processing: 2022-11-29\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[34/162] Processing: 2022-12-02\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[35/162] Processing: 2022-12-06\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[36/162] Processing: 2022-12-08\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[37/162] Processing: 2022-12-09\n",
      "   Records: 19\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[38/162] Processing: 2022-12-10\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[39/162] Processing: 2022-12-13\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[40/162] Processing: 2022-12-14\n",
      "   Records: 19\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 2 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[41/162] Processing: 2022-12-15\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[42/162] Processing: 2022-12-16\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[43/162] Processing: 2022-12-17\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[44/162] Processing: 2022-12-18\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[45/162] Processing: 2022-12-20\n",
      "   Records: 12\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[46/162] Processing: 2022-12-21\n",
      "   Records: 3\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[47/162] Processing: 2022-12-22\n",
      "   Records: 8\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[48/162] Processing: 2022-12-23\n",
      "   Records: 33\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 2 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[49/162] Processing: 2022-12-24\n",
      "   Records: 18\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[50/162] Processing: 2022-12-25\n",
      "   Records: 6\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[51/162] Processing: 2022-12-26\n",
      "   Records: 19\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 2 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[52/162] Processing: 2022-12-27\n",
      "   Records: 26\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 2 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[53/162] Processing: 2022-12-28\n",
      "   Records: 17\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 2 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[54/162] Processing: 2022-12-29\n",
      "   Records: 67\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 8 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[55/162] Processing: 2022-12-30\n",
      "   Records: 133\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 15 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[56/162] Processing: 2022-12-31\n",
      "   Records: 2,711\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 303 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[57/162] Processing: 2023-01-01\n",
      "   Records: 1,900,149\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 189,107 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[58/162] Processing: 2023-01-02\n",
      "   Records: 1,912,592\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 190,395 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[59/162] Processing: 2023-01-03\n",
      "   Records: 1,939,298\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 193,044 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[60/162] Processing: 2023-01-04\n",
      "   Records: 2,012,736\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 200,614 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[61/162] Processing: 2023-01-05\n",
      "   Records: 2,029,424\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 203,205 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[62/162] Processing: 2023-01-06\n",
      "   Records: 2,069,577\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 206,487 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[63/162] Processing: 2023-01-07\n",
      "   Records: 2,046,836\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 203,845 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[64/162] Processing: 2023-01-08\n",
      "   Records: 1,993,657\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 198,428 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[65/162] Processing: 2023-01-09\n",
      "   Records: 1,996,243\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 198,704 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[66/162] Processing: 2023-01-10\n",
      "   Records: 2,087,204\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 208,270 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[67/162] Processing: 2023-01-11\n",
      "   Records: 2,083,978\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 207,605 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[68/162] Processing: 2023-01-12\n",
      "   Records: 2,083,874\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 207,892 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[69/162] Processing: 2023-01-13\n",
      "   Records: 2,111,455\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 210,741 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[70/162] Processing: 2023-01-14\n",
      "   Records: 2,058,205\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 204,991 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[71/162] Processing: 2023-01-15\n",
      "   Records: 2,008,295\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 199,934 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[72/162] Processing: 2023-01-16\n",
      "   Records: 2,027,859\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 201,973 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[73/162] Processing: 2023-01-17\n",
      "   Records: 647,396\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 64,491 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[74/162] Processing: 2023-01-18\n",
      "   Records: 84\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 8 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[75/162] Processing: 2023-01-19\n",
      "   Records: 264,155\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 26,334 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[76/162] Processing: 2023-01-20\n",
      "   Records: 1,787,880\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 178,129 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[77/162] Processing: 2023-01-21\n",
      "   Records: 2,049,883\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 204,150 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[78/162] Processing: 2023-01-22\n",
      "   Records: 1,992,896\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 198,661 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[79/162] Processing: 2023-01-23\n",
      "   Records: 2,043,569\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 203,802 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[80/162] Processing: 2023-01-24\n",
      "   Records: 2,079,489\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 207,144 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[81/162] Processing: 2023-01-25\n",
      "   Records: 2,099,126\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 209,064 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[82/162] Processing: 2023-01-26\n",
      "   Records: 2,099,635\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 209,110 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[83/162] Processing: 2023-01-27\n",
      "   Records: 2,110,042\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 210,187 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[84/162] Processing: 2023-01-28\n",
      "   Records: 2,079,704\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 207,179 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[85/162] Processing: 2023-01-29\n",
      "   Records: 2,023,523\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 201,550 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[86/162] Processing: 2023-01-30\n",
      "   Records: 2,065,032\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 205,774 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[87/162] Processing: 2023-01-31\n",
      "   Records: 2,077,468\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 207,076 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[88/162] Processing: 2021-06-03\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[89/162] Processing: 2021-11-26\n",
      "   Records: 3\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[90/162] Processing: 2021-11-27\n",
      "   Records: 6\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[91/162] Processing: 2021-12-14\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[92/162] Processing: 2022-02-24\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[93/162] Processing: 2022-03-16\n",
      "   Records: 48\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 4 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[94/162] Processing: 2022-04-13\n",
      "   Records: 71\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 7 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[95/162] Processing: 2022-04-17\n",
      "   Records: 6\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[96/162] Processing: 2022-05-18\n",
      "   Records: 10\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 2 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[97/162] Processing: 2022-06-14\n",
      "   Records: 42\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 4 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[98/162] Processing: 2022-06-24\n",
      "   Records: 25\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 2 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[99/162] Processing: 2022-07-25\n",
      "   Records: 6\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[100/162] Processing: 2022-09-20\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[101/162] Processing: 2022-09-26\n",
      "   Records: 18\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 2 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[102/162] Processing: 2022-11-24\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[103/162] Processing: 2022-11-27\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[104/162] Processing: 2022-12-09\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[105/162] Processing: 2022-12-14\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[106/162] Processing: 2022-12-15\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[107/162] Processing: 2022-12-16\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[108/162] Processing: 2022-12-24\n",
      "   Records: 7\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[109/162] Processing: 2022-12-26\n",
      "   Records: 4\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[110/162] Processing: 2022-12-27\n",
      "   Records: 18\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 2 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[111/162] Processing: 2022-12-30\n",
      "   Records: 11\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[112/162] Processing: 2022-12-31\n",
      "   Records: 13\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[113/162] Processing: 2023-01-01\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[114/162] Processing: 2023-01-06\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[115/162] Processing: 2023-01-08\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[116/162] Processing: 2023-01-09\n",
      "   Records: 1\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[117/162] Processing: 2023-01-12\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[118/162] Processing: 2023-01-13\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[119/162] Processing: 2023-01-15\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[120/162] Processing: 2023-01-16\n",
      "   Records: 2\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 0 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[121/162] Processing: 2023-01-18\n",
      "   Records: 9\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[122/162] Processing: 2023-01-19\n",
      "   Records: 12\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[123/162] Processing: 2023-01-20\n",
      "   Records: 9\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[124/162] Processing: 2023-01-21\n",
      "   Records: 11\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 1 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[125/162] Processing: 2023-01-22\n",
      "   Records: 37\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 5 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[126/162] Processing: 2023-01-23\n",
      "   Records: 37\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 3 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[127/162] Processing: 2023-01-24\n",
      "   Records: 53\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 4 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[128/162] Processing: 2023-01-25\n",
      "   Records: 51\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 6 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[129/162] Processing: 2023-01-26\n",
      "   Records: 58\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 6 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[130/162] Processing: 2023-01-27\n",
      "   Records: 68\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 9 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[131/162] Processing: 2023-01-28\n",
      "   Records: 49\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 4 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[132/162] Processing: 2023-01-29\n",
      "   Records: 39\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 3 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[133/162] Processing: 2023-01-30\n",
      "   Records: 97\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 12 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[134/162] Processing: 2023-01-31\n",
      "   Records: 1,822\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 211 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[135/162] Processing: 2023-02-01\n",
      "   Records: 2,084,537\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 207,636 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[136/162] Processing: 2023-02-02\n",
      "   Records: 2,090,310\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 208,572 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[137/162] Processing: 2023-02-03\n",
      "   Records: 2,119,439\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 211,500 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[138/162] Processing: 2023-02-04\n",
      "   Records: 2,093,479\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 208,915 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[139/162] Processing: 2023-02-05\n",
      "   Records: 2,015,844\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 200,917 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[140/162] Processing: 2023-02-06\n",
      "   Records: 2,032,859\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 202,698 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[141/162] Processing: 2023-02-07\n",
      "   Records: 2,009,864\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 200,333 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[142/162] Processing: 2023-02-08\n",
      "   Records: 845,614\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 84,766 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[143/162] Processing: 2023-02-09\n",
      "   Records: 62\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 7 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[144/162] Processing: 2023-02-10\n",
      "   Records: 108\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 11 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[145/162] Processing: 2023-02-11\n",
      "   Records: 86\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 8 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[146/162] Processing: 2023-02-12\n",
      "   Records: 133\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 14 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[147/162] Processing: 2023-02-13\n",
      "   Records: 1,437,565\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 144,060 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[148/162] Processing: 2023-02-14\n",
      "   Records: 2,108,151\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 210,425 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[149/162] Processing: 2023-02-15\n",
      "   Records: 2,099,099\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 209,487 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[150/162] Processing: 2023-02-16\n",
      "   Records: 2,080,329\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 207,573 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[151/162] Processing: 2023-02-17\n",
      "   Records: 2,115,672\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 211,139 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[152/162] Processing: 2023-02-18\n",
      "   Records: 2,095,414\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 209,104 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[153/162] Processing: 2023-02-19\n",
      "   Records: 2,028,400\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 202,025 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[154/162] Processing: 2023-02-20\n",
      "   Records: 2,092,241\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 208,788 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[155/162] Processing: 2023-02-21\n",
      "   Records: 2,104,991\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 209,679 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[156/162] Processing: 2023-02-22\n",
      "   Records: 2,109,188\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 210,083 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[157/162] Processing: 2023-02-23\n",
      "   Records: 2,113,079\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 210,492 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[158/162] Processing: 2023-02-24\n",
      "   Records: 2,034,103\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 202,605 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[159/162] Processing: 2023-02-25\n",
      "   Records: 2,099,916\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 209,180 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[160/162] Processing: 2023-02-26\n",
      "   Records: 2,041,660\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 203,414 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "   ðŸ”„ Garbage collection triggered\n",
      "\n",
      "[161/162] Processing: 2023-02-27\n",
      "   Records: 2,072,871\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 206,568 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "[162/162] Processing: 2023-02-28\n",
      "   Records: 2,096,210\n",
      "   Converting timestamps to Bangkok timezone...\n",
      "   Sampled: 209,971 records\n",
      "   âœ“ Completed. Memory freed.\n",
      "\n",
      "================================================================================\n",
      "COMBINING SAMPLED DATA\n",
      "================================================================================\n",
      "\n",
      "Combining 162 sampled partitions...\n",
      "   Combined 20/162 partitions...\n",
      "   Combined 40/162 partitions...\n",
      "   Combined 60/162 partitions...\n",
      "   Combined 80/162 partitions...\n",
      "   Combined 100/162 partitions...\n",
      "   Combined 120/162 partitions...\n",
      "   Combined 140/162 partitions...\n",
      "   Combined 160/162 partitions...\n",
      "\n",
      "================================================================================\n",
      "LOADING SUMMARY\n",
      "================================================================================\n",
      "âœ“ Partitions processed: 162\n",
      "âœ“ Partitions loaded: 162\n",
      "âœ“ Total records processed: 105,808,920\n",
      "âœ“ Total records sampled: 10,548,553\n",
      "âœ“ Effective sample rate: 9.97%\n",
      "\n",
      "--- Schema ---\n",
      "root\n",
      " |-- vehicle_id: string (nullable = true)\n",
      " |-- gpsvalid: integer (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- lon: double (nullable = true)\n",
      " |-- timestamp_str: string (nullable = true)\n",
      " |-- speed: double (nullable = true)\n",
      " |-- heading: integer (nullable = true)\n",
      " |-- for_hire_light: integer (nullable = true)\n",
      " |-- engine_acc: integer (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      "\n",
      "\n",
      "--- Sample Data (with Bangkok timezone) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 18:24:51 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/11/24 18:24:51 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n",
      "25/11/24 18:24:51 WARN DAGScheduler: Broadcasting large task binary with size 2.1 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-------------------+--------+---------+-----+\n",
      "|vehicle_id                 |timestamp          |lat     |lon      |speed|\n",
      "+---------------------------+-------------------+--------+---------+-----+\n",
      "|ceA0iCVUC5bYCXyW+BpVQ90cAOY|2022-02-04 23:41:55|13.57436|100.81136|0.0  |\n",
      "|cBkMk2JO+U1KOHdagHkqb8SsHTY|2022-03-08 21:34:19|13.60358|100.70549|0.0  |\n",
      "|cBkMk2JO+U1KOHdagHkqb8SsHTY|2022-03-08 21:34:19|13.60358|100.70549|0.0  |\n",
      "|cBkMk2JO+U1KOHdagHkqb8SsHTY|2022-03-08 21:34:19|13.60358|100.70549|0.0  |\n",
      "|cBkMk2JO+U1KOHdagHkqb8SsHTY|2022-03-08 21:34:19|13.60358|100.70549|0.0  |\n",
      "|cBkMk2JO+U1KOHdagHkqb8SsHTY|2022-03-08 21:34:19|13.60358|100.70549|0.0  |\n",
      "|cBkMk2JO+U1KOHdagHkqb8SsHTY|2022-03-08 21:34:19|13.60358|100.70549|0.0  |\n",
      "|cBkMk2JO+U1KOHdagHkqb8SsHTY|2022-03-08 21:34:19|13.60358|100.70549|0.0  |\n",
      "|BjAsxpgR/cqNmc0t7rFPF4cuNG0|2022-03-12 14:53:09|13.76253|100.76036|0.0  |\n",
      "|bxpVwzv8diD+rzPxReeP9/eMm+o|2022-03-16 19:54:31|13.64605|100.59546|0.0  |\n",
      "+---------------------------+-------------------+--------+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n",
      "--- Timestamp Range (Bangkok Time) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 18:24:54 WARN DAGScheduler: Broadcasting large task binary with size 1688.2 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+-------------+\n",
      "|earliest_timestamp |latest_timestamp   |total_records|\n",
      "+-------------------+-------------------+-------------+\n",
      "|2022-02-04 23:41:55|2023-03-01 06:59:13|10548553     |\n",
      "+-------------------+-------------------+-------------+\n",
      "\n",
      "\n",
      "--- Date Distribution ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 18:25:01 WARN DAGScheduler: Broadcasting large task binary with size 2.6 MiB\n",
      "25/11/24 18:25:10 WARN DAGScheduler: Broadcasting large task binary with size 1484.9 KiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|date      |count|\n",
      "+----------+-----+\n",
      "|2022-02-04|1    |\n",
      "|2022-03-08|7    |\n",
      "|2022-03-12|1    |\n",
      "|2022-03-16|10   |\n",
      "|2022-04-13|15   |\n",
      "|2022-04-17|4    |\n",
      "|2022-05-18|4    |\n",
      "|2022-06-14|7    |\n",
      "|2022-06-24|10   |\n",
      "|2022-08-07|7    |\n",
      "|2022-09-27|10   |\n",
      "|2022-11-04|1    |\n",
      "|2022-11-11|1    |\n",
      "|2022-11-15|1    |\n",
      "|2022-12-09|1    |\n",
      "|2022-12-14|2    |\n",
      "|2022-12-20|1    |\n",
      "|2022-12-23|1    |\n",
      "|2022-12-24|1    |\n",
      "|2022-12-25|1    |\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1143:==============================================>     (656 + 8) / 740]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial record count: 10,548,553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# DATA LOADING WITH SAMPLING (Memory-Safe Daily File Processing)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LOADING DATA FROM DAILY PARQUET FILES WITH SAMPLING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "SAMPLE_FRACTION = 0.10  # 10% sample\n",
    "BANGKOK_TIMEZONE = \"Asia/Bangkok\"  # GMT+7\n",
    "MIN_DATE = \"2021-01-01\"  # Filter out invalid dates (include 2021 onwards)\n",
    "\n",
    "# Base paths containing Hive partitioned data\n",
    "base_paths = [\"PARQUET-PROBE-202301\", \"PARQUET-PROBE-202302\"]\n",
    "\n",
    "# Collect all daily partitions\n",
    "all_daily_partitions = []\n",
    "\n",
    "for base_path in base_paths:\n",
    "    if os.path.exists(base_path):\n",
    "        # Find all date=YYYY-MM-DD subdirectories\n",
    "        date_partitions = glob.glob(f\"{base_path}/date=*\")\n",
    "        \n",
    "        # Filter out invalid dates (before 2023-01-01)\n",
    "        for partition in date_partitions:\n",
    "            # Extract date from partition name\n",
    "            date_str = partition.split(\"date=\")[-1]\n",
    "            try:\n",
    "                # Validate date format and filter\n",
    "                partition_date = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "                if partition_date >= datetime.strptime(MIN_DATE, \"%Y-%m-%d\"):\n",
    "                    all_daily_partitions.append(partition)\n",
    "            except ValueError:\n",
    "                print(f\"   âš  Skipping invalid date partition: {partition}\")\n",
    "                continue\n",
    "\n",
    "# Sort partitions by date\n",
    "all_daily_partitions.sort()\n",
    "\n",
    "print(f\"\\nFound {len(all_daily_partitions)} valid daily partitions (from {MIN_DATE} onwards)\")\n",
    "print(f\"Sample fraction: {SAMPLE_FRACTION * 100}%\")\n",
    "print(f\"Date range: {all_daily_partitions[0].split('=')[-1]} to {all_daily_partitions[-1].split('=')[-1]}\")\n",
    "\n",
    "if not all_daily_partitions:\n",
    "    raise ValueError(f\"No valid partitions found after {MIN_DATE}!\")\n",
    "\n",
    "# Process partitions one by one and accumulate samples\n",
    "sampled_dfs = []\n",
    "total_records_processed = 0\n",
    "total_records_sampled = 0\n",
    "failed_partitions = []\n",
    "\n",
    "for idx, partition_path in enumerate(all_daily_partitions, 1):\n",
    "    try:\n",
    "        partition_date = partition_path.split(\"date=\")[-1]\n",
    "        print(f\"\\n[{idx}/{len(all_daily_partitions)}] Processing: {partition_date}\")\n",
    "        \n",
    "        # Load single daily partition\n",
    "        df_daily = spark.read.parquet(partition_path)\n",
    "        \n",
    "        # Get record count (fast with parquet metadata)\n",
    "        daily_count = df_daily.count()\n",
    "        \n",
    "        if daily_count == 0:\n",
    "            print(f\"   âš  Empty partition, skipping...\")\n",
    "            continue\n",
    "            \n",
    "        print(f\"   Records: {daily_count:,}\")\n",
    "        \n",
    "        # Take 10% sample with fixed seed for reproducibility\n",
    "        df_sample = df_daily.sample(withReplacement=False, fraction=SAMPLE_FRACTION, seed=42)\n",
    "        \n",
    "        # Convert timestamp to Bangkok timezone (GMT+7)\n",
    "        print(f\"   Converting timestamps to Bangkok timezone...\")\n",
    "        \n",
    "        # Handle different timestamp formats\n",
    "        df_sample = df_sample.withColumn(\"timestamp_raw\", F.col(\"timestamp\"))\n",
    "        \n",
    "        # Convert to timestamp type\n",
    "        df_sample = df_sample.withColumn(\"timestamp\",\n",
    "            # If Unix epoch in seconds (< 10 billion)\n",
    "            F.when(F.col(\"timestamp\").cast(\"long\") < 10000000000,\n",
    "                   F.from_unixtime(F.col(\"timestamp\").cast(\"long\")))\n",
    "            # If Unix epoch in milliseconds\n",
    "            .when(F.col(\"timestamp\").cast(\"long\") >= 10000000000,\n",
    "                  F.from_unixtime(F.col(\"timestamp\").cast(\"long\") / 1000))\n",
    "            # If already timestamp/string\n",
    "            .otherwise(F.to_timestamp(F.col(\"timestamp\")))\n",
    "        )\n",
    "        \n",
    "        # Ensure proper timestamp type\n",
    "        df_sample = df_sample.withColumn(\"timestamp\",\n",
    "            F.to_timestamp(F.col(\"timestamp\"))\n",
    "        )\n",
    "        \n",
    "        # Convert from UTC to Bangkok timezone (GMT+7)\n",
    "        df_sample = df_sample.withColumn(\"timestamp\",\n",
    "            F.from_utc_timestamp(F.col(\"timestamp\"), BANGKOK_TIMEZONE)\n",
    "        )\n",
    "        \n",
    "        # Drop temporary column\n",
    "        df_sample = df_sample.drop(\"timestamp_raw\")\n",
    "        \n",
    "        # Get sample count\n",
    "        sample_count = df_sample.count()\n",
    "        print(f\"   Sampled: {sample_count:,} records\")\n",
    "        \n",
    "        # Add to collection\n",
    "        sampled_dfs.append(df_sample)\n",
    "        \n",
    "        # Immediately free memory from full daily dataframe\n",
    "        df_daily.unpersist()\n",
    "        del df_daily\n",
    "        \n",
    "        # Update totals\n",
    "        total_records_processed += daily_count\n",
    "        total_records_sampled += sample_count\n",
    "        \n",
    "        print(f\"   âœ“ Completed. Memory freed.\")\n",
    "        \n",
    "        # Periodic garbage collection every 10 partitions\n",
    "        if idx % 10 == 0:\n",
    "            import gc\n",
    "            gc.collect()\n",
    "            print(f\"   ðŸ”„ Garbage collection triggered\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   âŒ Error processing {partition_path}: {str(e)}\")\n",
    "        failed_partitions.append(partition_path)\n",
    "        continue\n",
    "\n",
    "# Combine all sampled dataframes\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMBINING SAMPLED DATA\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "if not sampled_dfs:\n",
    "    raise ValueError(\"No data was loaded successfully!\")\n",
    "\n",
    "print(f\"\\nCombining {len(sampled_dfs)} sampled partitions...\")\n",
    "\n",
    "# Union all samples efficiently\n",
    "df = sampled_dfs[0]\n",
    "for i, sample_df in enumerate(sampled_dfs[1:], 2):\n",
    "    df = df.union(sample_df)\n",
    "    if i % 20 == 0:\n",
    "        print(f\"   Combined {i}/{len(sampled_dfs)} partitions...\")\n",
    "\n",
    "# Free memory from individual samples\n",
    "for sample_df in sampled_dfs:\n",
    "    sample_df.unpersist()\n",
    "del sampled_dfs\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"LOADING SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"âœ“ Partitions processed: {len(all_daily_partitions)}\")\n",
    "print(f\"âœ“ Partitions loaded: {len(all_daily_partitions) - len(failed_partitions)}\")\n",
    "if failed_partitions:\n",
    "    print(f\"âš  Partitions failed: {len(failed_partitions)}\")\n",
    "print(f\"âœ“ Total records processed: {total_records_processed:,}\")\n",
    "print(f\"âœ“ Total records sampled: {total_records_sampled:,}\")\n",
    "print(f\"âœ“ Effective sample rate: {(total_records_sampled/total_records_processed*100):.2f}%\")\n",
    "\n",
    "print(f\"\\n--- Schema ---\")\n",
    "df.printSchema()\n",
    "\n",
    "print(\"\\n--- Sample Data (with Bangkok timezone) ---\")\n",
    "df.select(\"vehicle_id\", \"timestamp\", \"lat\", \"lon\", \"speed\").show(10, truncate=False)\n",
    "\n",
    "print(f\"\\n--- Timestamp Range (Bangkok Time) ---\")\n",
    "df.select(\n",
    "    F.min(\"timestamp\").alias(\"earliest_timestamp\"),\n",
    "    F.max(\"timestamp\").alias(\"latest_timestamp\"),\n",
    "    F.count(\"*\").alias(\"total_records\")\n",
    ").show(truncate=False)\n",
    "\n",
    "print(f\"\\n--- Date Distribution ---\")\n",
    "df.groupBy(F.to_date(\"timestamp\").alias(\"date\")) \\\n",
    "    .count() \\\n",
    "    .orderBy(\"date\") \\\n",
    "    .show(20, truncate=False)\n",
    "\n",
    "print(f\"Initial record count: {df.count():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916170df",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d58381c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING DATA CLEANSING\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "STARTING OPTIMIZED DATA CLEANSING\n",
      "================================================================================\n",
      "\n",
      "1. Applying all filters and basic transformations in single pass...\n",
      "âœ“ Filtering and deduplication complete\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# DATA CLEANSING\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING DATA CLEANSING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ==============================================================================\n",
    "# OPTIMIZED DATA CLEANSING (Single Pass)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING OPTIMIZED DATA CLEANSING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# OPTIMIZATION 1: Combine ALL filters and transformations in ONE pass\n",
    "print(\"\\n1. Applying all filters and basic transformations in single pass...\")\n",
    "\n",
    "df = df.filter(\n",
    "    # Timestamp filter - include 2021 onwards\n",
    "    (F.col(\"timestamp\") >= \"2021-01-01\") &\n",
    "    # GPS validity\n",
    "    ((F.col(\"gpsvalid\") == 1) | ((F.col(\"lat\") != 0.0) & (F.col(\"lon\") != 0.0))) &\n",
    "    # Thailand bounds\n",
    "    (F.col(\"lat\").between(5.6, 20.5)) & (F.col(\"lon\").between(97.3, 105.6))\n",
    ").select(\n",
    "    # Keep only necessary columns, drop unused ones early\n",
    "    \"vehicle_id\",\n",
    "    \"timestamp\",\n",
    "    \"lat\",\n",
    "    \"lon\",\n",
    "    F.when(F.col(\"speed\") > 150, 150)\n",
    "     .when(F.col(\"speed\") < 0, 0)\n",
    "     .otherwise(F.coalesce(F.col(\"speed\"), F.lit(0))).alias(\"speed\"),\n",
    "    F.coalesce(F.col(\"heading\"), F.lit(0)).alias(\"heading\"),\n",
    "    \"for_hire_light\",\n",
    "    \"engine_acc\",\n",
    "    \"gpsvalid\"\n",
    ").dropDuplicates([\"vehicle_id\", \"timestamp\", \"lat\", \"lon\"])\n",
    "\n",
    "print(f\"âœ“ Filtering and deduplication complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3c5e71",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98ce0c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING OPTIMIZED FEATURE ENGINEERING\n",
      "================================================================================\n",
      "\n",
      "1. Creating temporal, spatial, and activity features (single pass)...\n",
      "1b. Filtering to keep only data within Bangkok Metropolitan Region (BMR)...\n",
      "âœ“ Filter applied. Data outside BMR has been removed.\n",
      "2. Calculating derived spatial features and adding tourist proxies...\n",
      "âœ“ Optimized temporal, spatial, activity, and tourist features created successfully.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# ==============================================================================\n",
    "# OPTIMIZED FEATURE ENGINEERING (Batch Operations)\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STARTING OPTIMIZED FEATURE ENGINEERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define constants and helper functions\n",
    "# ---\n",
    "\n",
    "# Bangkok Metropolitan Region (BMR) Province Centers (lat, lon)\n",
    "province_centers: Dict[str, Tuple[float, float]] = {\n",
    "    'bangkok': (13.7563, 100.5018),\n",
    "    'nakhon_pathom': (13.8199, 100.0622),\n",
    "    'pathum_thani': (14.0208, 100.5250),\n",
    "    'nonthaburi': (13.8621, 100.5144),\n",
    "    'samut_prakan': (13.5990, 100.5998),\n",
    "    'samut_sakhon': (13.5475, 100.2744)\n",
    "}\n",
    "\n",
    "# Haversine distance calculation in km (using Spark SQL functions)\n",
    "# The formula calculates the great-circle distance between two points on a sphere.\n",
    "def haversine_distance_km(lat_col, lon_col, center_lat, center_lon) -> F.Column:\n",
    "    \"\"\"Calculates the Haversine distance between a point (lat_col, lon_col)\n",
    "    and a fixed center (center_lat, center_lon) in kilometers.\"\"\"\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    \n",
    "    # Calculate angular distance 'c' using the formula\n",
    "    c = F.acos(\n",
    "        F.sin(F.radians(lat_col)) * F.sin(F.radians(F.lit(center_lat))) +\n",
    "        F.cos(F.radians(lat_col)) * F.cos(F.radians(F.lit(center_lat))) *\n",
    "        F.cos(F.radians(lon_col) - F.radians(F.lit(center_lon)))\n",
    "    )\n",
    "    return c * R\n",
    "\n",
    "# ---\n",
    "\n",
    "# OPTIMIZATION: Create ALL non-window features in ONE transformation\n",
    "print(\"\\n1. Creating temporal, spatial, and activity features (single pass)...\")\n",
    "\n",
    "# Bangkok Metropolitan Region Boundaries (approximate)\n",
    "bmr_lat_min, bmr_lat_max = 13.4, 14.2\n",
    "bmr_lon_min, bmr_lon_max = 100.0, 100.9\n",
    "\n",
    "# Create distance columns using the helper function\n",
    "distance_cols = [\n",
    "    haversine_distance_km(F.col(\"lat\"), F.col(\"lon\"), lat, lon).alias(f\"distance_from_{name}_km\")\n",
    "    for name, (lat, lon) in province_centers.items()\n",
    "]\n",
    "\n",
    "df = df.select(\n",
    "    \"*\",\n",
    "    # === TEMPORAL FEATURES ===\n",
    "    F.hour(\"timestamp\").alias(\"hour\"),\n",
    "    # 0=Sunday, 1=Monday... 6=Saturday (F.dayofweek() returns 1=Sun, 7=Sat)\n",
    "    (F.dayofweek(\"timestamp\") - 1).alias(\"day_of_week\"), \n",
    "    F.date_format(\"timestamp\", \"EEEE\").alias(\"day_name\"),\n",
    "    # FIXED: is_weekend now correctly flags F.dayofweek() 1 (Sunday) and 7 (Saturday)\n",
    "    F.when(F.dayofweek(\"timestamp\").isin([1, 7]), 1).otherwise(0).alias(\"is_weekend\"),\n",
    "    F.month(\"timestamp\").alias(\"month\"),\n",
    "    F.year(\"timestamp\").alias(\"year\"),\n",
    "    F.to_date(\"timestamp\").alias(\"date_only\"),\n",
    "    \n",
    "    # Time of day (More detailed, supports various persona needs)\n",
    "    F.when(F.hour(\"timestamp\").between(5, 11), \"morning\")    # 05:00 - 11:59\n",
    "     .when(F.hour(\"timestamp\").between(12, 16), \"afternoon\") # 12:00 - 16:59\n",
    "     .when(F.hour(\"timestamp\").between(17, 20), \"evening\")   # 17:00 - 20:59\n",
    "     .otherwise(\"night\").alias(\"time_of_day\"),               # 21:00 - 04:59\n",
    "    \n",
    "    # Generic Day/Night Indicator (Crucial for Personas)\n",
    "    # Day Shift (e.g., 06:00-17:59) vs Night Shift (e.g., 18:00-05:59)\n",
    "    F.when(F.hour(\"timestamp\").between(6, 17), \"day_shift\")\n",
    "      .otherwise(\"night_shift\").alias(\"day_night_shift\"),\n",
    "    \n",
    "    # Rush hour (aligned for high traffic/demand)\n",
    "    F.when(F.hour(\"timestamp\").isin([7, 8, 9, 17, 18, 19]), 1).otherwise(0).alias(\"is_rush_hour\"),\n",
    "    \n",
    "    # === VEHICLE ACTIVITY FEATURES (Supports TK & Nipun) ===\n",
    "    # Trip-Defining Logic (for Taxi Fleet Manager TK)\n",
    "    # Assumes 'for_hire_light' == 0 AND 'engine_acc' == 1 means HIRED/OCCUPIED.\n",
    "    F.when((F.col(\"for_hire_light\") == 0) & (F.col(\"engine_acc\") == 1), 1).otherwise(0).alias(\"is_hired\"),\n",
    "    \n",
    "    # Proxy for Searching for Passenger (Taxi Deserts for City Planner Chana)\n",
    "    # 'for_hire_light' == 1 (light ON) AND 'engine_acc' == 1 means VACANT and MOVING.\n",
    "    F.when((F.col(\"for_hire_light\") == 1) & (F.col(\"engine_acc\") == 1), 1).otherwise(0).alias(\"is_searching_fare\"),\n",
    "    \n",
    "    # Idle/Stationary Status\n",
    "    F.when(F.col(\"engine_acc\") == 0, 1).otherwise(0).alias(\"is_idle\"),\n",
    "    F.when(F.col(\"speed\") > 3, 1).otherwise(0).alias(\"is_moving\"),\n",
    "    F.when(F.col(\"speed\") <= 3, 1).otherwise(0).alias(\"is_stationary\"),\n",
    "    \n",
    "    # Speed category\n",
    "    F.when(F.col(\"speed\") <= 3, \"stationary\")\n",
    "      .when(F.col(\"speed\") <= 30, \"slow\")\n",
    "      .when(F.col(\"speed\") <= 60, \"moderate\")\n",
    "      .when(F.col(\"speed\") <= 90, \"fast\")\n",
    "      .otherwise(\"very_fast\").alias(\"speed_category\"),\n",
    "    \n",
    "    # === SPATIAL FEATURES - Bangkok Metropolitan Region ===\n",
    "    # Apply the Haversine distance columns\n",
    "    *distance_cols,\n",
    "    \n",
    "    # Flag for Bangkok Metropolitan Region\n",
    "    F.when(\n",
    "        (F.col(\"lat\").between(bmr_lat_min, bmr_lat_max)) &\n",
    "        (F.col(\"lon\").between(bmr_lon_min, bmr_lon_max)),\n",
    "        1\n",
    "    ).otherwise(0).alias(\"is_in_bmr\"),\n",
    "    \n",
    "    # Grid cells (for hotspot analysis - Chana)\n",
    "    (F.round(F.col(\"lat\") * 100) / 100).alias(\"lat_grid\"), # 100 = ~1.1km grid\n",
    "    (F.round(F.col(\"lon\") * 100) / 100).alias(\"lon_grid\")\n",
    ")\n",
    "\n",
    "# ðŸš¨ NEW FILTER STEP ADDED HERE ðŸš¨\n",
    "# Filter the DataFrame to keep only records within the BMR.\n",
    "print(\"1b. Filtering to keep only data within Bangkok Metropolitan Region (BMR)...\")\n",
    "df = df.filter(F.col(\"is_in_bmr\") == 1)\n",
    "print(\"âœ“ Filter applied. Data outside BMR has been removed.\")\n",
    "\n",
    "# ---\n",
    "print(\"2. Calculating derived spatial features and adding tourist proxies...\")\n",
    "\n",
    "# Create a list of distance column names\n",
    "distance_col_names = [f\"distance_from_{name}_km\" for name in province_centers.keys()]\n",
    "\n",
    "# Add derived spatial features (depends on previous calculations)\n",
    "df = df.withColumn(\"distance_to_nearest_center_km\",\n",
    "    F.least(*[F.col(c) for c in distance_col_names])\n",
    ")\n",
    "\n",
    "# Identify nearest province center \n",
    "nearest_province_expression = None\n",
    "province_names = list(province_centers.keys())\n",
    "\n",
    "for name in province_names:\n",
    "    col_name = f\"distance_from_{name}_km\"\n",
    "    province_display_name = name.replace('_', ' ').title()\n",
    "    \n",
    "    condition = (F.col(\"distance_to_nearest_center_km\") == F.col(col_name))\n",
    "    \n",
    "    if nearest_province_expression is None:\n",
    "        nearest_province_expression = F.when(condition, province_display_name)\n",
    "    else:\n",
    "        # Use otherwise to chain the conditions\n",
    "        nearest_province_expression = nearest_province_expression.when(condition, province_display_name)\n",
    "\n",
    "# Finalize the expression with an otherwise clause\n",
    "# Since we filtered out data where is_in_bmr was 0, the 'Outside BMR' clause here is theoretically only for edge cases \n",
    "# or where the BMR coordinates were slightly different from the province center definitions.\n",
    "df = df.withColumn(\"nearest_province\",\n",
    "    nearest_province_expression.otherwise(\"Outside BMR/Edge Case\")\n",
    ")\n",
    "\n",
    "# Area classification based on distance from Bangkok center\n",
    "df = df.withColumn(\"area_type\",\n",
    "    F.when(F.col(\"distance_from_bangkok_km\") <= 5, \"bangkok_center_core\") # <= 5km\n",
    "      .when(F.col(\"distance_from_bangkok_km\") <= 15, \"bangkok_inner_ring\") # 5-15km\n",
    "      .when(F.col(\"distance_from_bangkok_km\") <= 30, \"bangkok_outer_belt\") # 15-30km\n",
    "      # The check F.col(\"is_in_bmr\") == 1 is now redundant since we filtered the data\n",
    "      .otherwise(\"bmr_suburban_area\") # If not in the rings, but still in BMR\n",
    ")\n",
    "\n",
    "# Add grid cell identifier\n",
    "df = df.withColumn(\"grid_cell\", \n",
    "    F.concat_ws(\"_\", F.col(\"lat_grid\"), F.col(\"lon_grid\"))\n",
    ")\n",
    "\n",
    "\n",
    "# === NEW TOURIST PROXY FEATURES (Calculated only on BMR data) ===\n",
    "# --- Bangkok's Major Tourist Hubs and Airports (Approximate lat/lon) ---\n",
    "# Suvarnabhumi Airport (BKK)\n",
    "BKK_lat, BKK_lon = 13.6900, 100.7501 \n",
    "# Don Mueang Airport (DMK)\n",
    "DMK_lat, DMK_lon = 13.9138, 100.6015 \n",
    "# Grand Palace / Old City Center (Major Tourist Area)\n",
    "PALACE_lat, PALACE_lon = 13.7500, 100.4917 \n",
    "# Chatuchak Weekend Market\n",
    "JJ_lat, JJ_lon = 13.8037, 100.5516\n",
    "\n",
    "# Calculate distance to major destinations\n",
    "df = df.withColumn(\"distance_to_bkk_airport_km\",\n",
    "    haversine_distance_km(F.col(\"lat\"), F.col(\"lon\"), BKK_lat, BKK_lon)\n",
    ").withColumn(\"distance_to_dmk_airport_km\",\n",
    "    haversine_distance_km(F.col(\"lat\"), F.col(\"lon\"), DMK_lat, DMK_lon)\n",
    ").withColumn(\"distance_to_grand_palace_km\",\n",
    "    haversine_distance_km(F.col(\"lat\"), F.col(\"lon\"), PALACE_lat, PALACE_lon)\n",
    ").withColumn(\"distance_to_chatuchak_km\",\n",
    "    haversine_distance_km(F.col(\"lat\"), F.col(\"lon\"), JJ_lat, JJ_lon)\n",
    ")\n",
    "\n",
    "# Feature 1: Proximity to Key Tourist Hubs/Airports\n",
    "# A point is considered a 'tourism destination' if it's close to EITHER of the major areas.\n",
    "# Thresholds: 5km for Airports (pick-up/drop-off), 2km for Palace/Chatuchak (dense activity).\n",
    "df = df.withColumn(\"is_near_tourist_hub\",\n",
    "    F.when(\n",
    "        (F.col(\"distance_to_bkk_airport_km\") <= 5) |\n",
    "        (F.col(\"distance_to_dmk_airport_km\") <= 5) |\n",
    "        (F.col(\"distance_to_grand_palace_km\") <= 2) |\n",
    "        (F.col(\"distance_to_chatuchak_km\") <= 2),\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Feature 2: Time Window for Tourist Activity\n",
    "# Standard tourist hours: 9am-6pm (excluding the early-morning workday commute, 7-9am).\n",
    "# We'll use day_of_week (0=Sun, 6=Sat) and hour.\n",
    "df = df.withColumn(\"is_tourist_time\",\n",
    "    F.when(\n",
    "        # Weekend\n",
    "        (F.col(\"day_of_week\").isin([0, 6])) | \n",
    "        # Weekday during mid-day (after morning rush, before evening rush)\n",
    "        ((F.col(\"day_of_week\").between(1, 5)) & (F.col(\"hour\").between(10, 16))), \n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "\n",
    "# Feature 3: FINAL Proxy - High Possibility of Tourist\n",
    "# Combines: Near a Hub AND It's Tourist Time AND NOT Rush Hour\n",
    "# This creates a strong signal for non-commuter activity near tourist areas.\n",
    "df = df.withColumn(\"is_tourist_activity_proxy\",\n",
    "    F.when(\n",
    "        (F.col(\"is_near_tourist_hub\") == 1) & \n",
    "        (F.col(\"is_tourist_time\") == 1) &\n",
    "        (F.col(\"is_rush_hour\") == 0) &\n",
    "        (F.col(\"is_hired\") == 1), # Only consider if the taxi is actually hired/occupied\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Feature 4: Taxi Pick-up/Drop-off near Airports (Crucial for demand analysis)\n",
    "# Flagging records that are very close to an airport AND the taxi is hired/occupied.\n",
    "df = df.withColumn(\"is_airport_fare_area\",\n",
    "    F.when(\n",
    "        (F.col(\"is_hired\") == 1) &\n",
    "        ((F.col(\"distance_to_bkk_airport_km\") <= 1) | (F.col(\"distance_to_dmk_airport_km\") <= 1)), # Very close proximity (1km)\n",
    "        1\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "\n",
    "# ---\n",
    "print(\"âœ“ Optimized temporal, spatial, activity, and tourist features created successfully.\")\n",
    "print(\"=\" * 80)\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e775e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Optimizing data layout for window operations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 18:25:41 WARN DAGScheduler: Broadcasting large task binary with size 3.8 MiB\n",
      "25/11/24 18:25:53 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Repartitioning to 57 partitions by vehicle_id...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 18:25:53 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "25/11/24 18:25:55 WARN DAGScheduler: Broadcasting large task binary with size 5.4 MiB\n",
      "25/11/24 18:26:13 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "25/11/24 18:26:43 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/11/24 18:26:54 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "[Stage 1160:====================================>                 (39 + 8) / 57]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Data repartitioned and cached\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# OPTIMIZATION 3: Efficient repartitioning for window operations\n",
    "print(\"\\n2. Optimizing data layout for window operations...\")\n",
    "num_vehicles = df.select(\"vehicle_id\").distinct().count()\n",
    "optimal_partitions = min(200, max(50, int(num_vehicles ** 0.5)))\n",
    "print(f\"   Repartitioning to {optimal_partitions} partitions by vehicle_id...\")\n",
    "\n",
    "df = df.repartition(optimal_partitions, \"vehicle_id\").sortWithinPartitions(\"vehicle_id\", \"timestamp\")\n",
    "df.cache()\n",
    "df.count()  # Materialize cache\n",
    "print(\"âœ“ Data repartitioned and cached\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a91274b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3. Creating window-based features (optimized single pass)...\n",
      "âœ“ Window-based features created\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZATION 4: Create ALL window-based features in ONE pass\n",
    "print(\"\\n3. Creating window-based features (optimized single pass)...\")\n",
    "\n",
    "window_lag = Window.partitionBy(\"vehicle_id\").orderBy(\"timestamp\")\n",
    "\n",
    "df = df.withColumn(\"prev_lat\", F.lag(\"lat\").over(window_lag)) \\\n",
    "    .withColumn(\"prev_lon\", F.lag(\"lon\").over(window_lag)) \\\n",
    "    .withColumn(\"prev_for_hire\", F.lag(\"for_hire_light\").over(window_lag)) \\\n",
    "    .withColumn(\"time_diff_seconds\", \n",
    "        (F.col(\"timestamp\").cast(\"long\") - F.lag(\"timestamp\").over(window_lag).cast(\"long\")))\n",
    "\n",
    "# Calculate distance traveled (vectorized Haversine)\n",
    "df = df.withColumn(\"distance_traveled_km\",\n",
    "    F.when(F.col(\"prev_lat\").isNotNull(),\n",
    "        F.acos(\n",
    "            F.sin(F.radians(F.col(\"prev_lat\"))) * F.sin(F.radians(F.col(\"lat\"))) +\n",
    "            F.cos(F.radians(F.col(\"prev_lat\"))) * F.cos(F.radians(F.col(\"lat\"))) *\n",
    "            F.cos(F.radians(F.col(\"lon\")) - F.radians(F.col(\"prev_lon\")))\n",
    "        ) * 6371\n",
    "    ).otherwise(0)\n",
    ")\n",
    "\n",
    "# Calculated speed, trip markers, cardinal direction - all in one pass\n",
    "df = df.select(\n",
    "    \"*\",\n",
    "    # Calculated speed\n",
    "    F.when(F.col(\"time_diff_seconds\") > 0,\n",
    "           (F.col(\"distance_traveled_km\") / F.col(\"time_diff_seconds\")) * 3600)\n",
    "     .otherwise(0).alias(\"calculated_speed_kmh\"),\n",
    "    \n",
    "    # Trip start/end\n",
    "    F.when((F.col(\"prev_for_hire\") == 1) & (F.col(\"for_hire_light\") == 0), 1).otherwise(0).alias(\"trip_start\"),\n",
    "    F.when((F.col(\"prev_for_hire\") == 0) & (F.col(\"for_hire_light\") == 1), 1).otherwise(0).alias(\"trip_end\"),\n",
    "    \n",
    "    # Cardinal direction (simplified)\n",
    "    F.when(F.col(\"heading\").between(337.5, 360) | F.col(\"heading\").between(0, 22.5), \"N\")\n",
    "     .when(F.col(\"heading\").between(22.5, 67.5), \"NE\")\n",
    "     .when(F.col(\"heading\").between(67.5, 112.5), \"E\")\n",
    "     .when(F.col(\"heading\").between(112.5, 157.5), \"SE\")\n",
    "     .when(F.col(\"heading\").between(157.5, 202.5), \"S\")\n",
    "     .when(F.col(\"heading\").between(202.5, 247.5), \"SW\")\n",
    "     .when(F.col(\"heading\").between(247.5, 292.5), \"W\")\n",
    "     .when(F.col(\"heading\").between(292.5, 337.5), \"NW\")\n",
    "     .otherwise(\"N\").alias(\"cardinal_direction\"),\n",
    "    \n",
    "    # Stop duration and quality flags\n",
    "    F.when((F.col(\"is_stationary\") == 1) & F.col(\"time_diff_seconds\").isNotNull(),\n",
    "           F.col(\"time_diff_seconds\")).otherwise(0).alias(\"stop_duration\"),\n",
    "    \n",
    "    F.when(F.col(\"engine_acc\") == 1, 1).otherwise(3).alias(\"normal_frequency\")\n",
    ")\n",
    "\n",
    "# Add derived behavioral features\n",
    "df = df.withColumn(\"is_long_stop\", F.when(F.col(\"stop_duration\") > 300, 1).otherwise(0)) \\\n",
    "    .withColumn(\"data_quality_flag\",\n",
    "        F.when(F.abs((F.col(\"time_diff_seconds\") / 60) - F.col(\"normal_frequency\")) > 2, \"irregular\")\n",
    "         .otherwise(\"normal\")) \\\n",
    "    .withColumn(\"speed_validation_flag\",\n",
    "        F.when((F.col(\"calculated_speed_kmh\").isNotNull()) & \n",
    "               (F.abs(F.col(\"calculated_speed_kmh\") - F.col(\"speed\")) > 20), \"mismatch\")\n",
    "         .otherwise(\"ok\"))\n",
    "\n",
    "print(\"âœ“ Window-based features created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9533de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4. Creating daily aggregated features (optimized)...\n",
      "âœ“ Daily aggregated features created and joined (optimized)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# OPTIMIZATION 5: Daily aggregations with single groupBy\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n4. Creating daily aggregated features (optimized)...\")\n",
    "\n",
    "# --- CORRECTIONS & ENHANCEMENTS ---\n",
    "# 1. 'likely_has_passenger' is replaced by 'is_hired'.\n",
    "# 2. 'likely_vacant' is replaced by 'is_searching_fare' (more specific).\n",
    "# 3. Added 'is_idle' and 'is_stationary' sums for operational insight (TK/Chana).\n",
    "# 4. Added count of Day/Night shifts for shift planning (TK/Nipun).\n",
    "# 5. Assume 'distance_traveled_km', 'trip_start', and 'trip_end' are available \n",
    "#    from a prior window function (Optimization 3/4).\n",
    "# ----------------------------------\n",
    "\n",
    "daily_stats = df.groupBy(\"vehicle_id\", \"date_only\").agg(\n",
    "    F.count(\"*\").alias(\"daily_ping_count\"),\n",
    "    \n",
    "    # === Vehicle Performance ===\n",
    "    F.mean(\"speed\").alias(\"daily_avg_speed\"),\n",
    "    F.max(\"speed\").alias(\"daily_max_speed\"),\n",
    "    F.sum(\"distance_traveled_km\").alias(\"daily_total_distance_km\"),\n",
    "    \n",
    "    # === Activity Counts (TK/Nipun/Chana) ===\n",
    "    # Total time/pings spent hired (Hired Revenue/Utilization)\n",
    "    F.sum(\"is_hired\").alias(\"daily_hired_pings\"),\n",
    "    # Total time/pings spent searching for fares (Empty Miles Proxy)\n",
    "    F.sum(\"is_searching_fare\").alias(\"daily_searching_fare_pings\"), \n",
    "    # Total time/pings spent idle (Operational Cost/Waste)\n",
    "    F.sum(\"is_idle\").alias(\"daily_idle_pings\"),\n",
    "    F.sum(\"is_stationary\").alias(\"daily_stationary_pings\"),\n",
    "    F.sum(\"is_moving\").alias(\"daily_moving_pings\"),\n",
    "    \n",
    "    # === Trip Counts (TK/Chana) ===\n",
    "    F.sum(\"trip_start\").alias(\"daily_trip_starts\"),\n",
    "    F.sum(\"trip_end\").alias(\"daily_trip_ends\"),\n",
    "    \n",
    "    # === Shift Metrics (Nipun/TK) ===\n",
    "    # Count of pings during Day vs. Night Shift for capacity analysis\n",
    "    F.sum(F.when(F.col(\"day_night_shift\") == \"day_shift\", 1).otherwise(0)).alias(\"daily_day_shift_pings\"),\n",
    "    F.sum(F.when(F.col(\"day_night_shift\") == \"night_shift\", 1).otherwise(0)).alias(\"daily_night_shift_pings\"),\n",
    "    \n",
    "    # === Spatial Metrics ===\n",
    "    # Total pings within the defined BMR boundaries\n",
    "    F.sum(\"is_in_bmr\").alias(\"daily_bmr_pings\")\n",
    ")\n",
    "\n",
    "# Broadcast join for small aggregation table (Standard practice)\n",
    "df = df.join(F.broadcast(daily_stats), on=[\"vehicle_id\", \"date_only\"], how=\"left\")\n",
    "\n",
    "\n",
    "# Add derived daily metrics\n",
    "# ---\n",
    "\n",
    "# Add utilization rate (Supports TK's Revenue/Fleet Management)\n",
    "df = df.withColumn(\"daily_utilization_rate\",\n",
    "    F.when(F.col(\"daily_ping_count\") > 0,\n",
    "           F.col(\"daily_hired_pings\") / F.col(\"daily_ping_count\"))\n",
    "     .otherwise(0))\n",
    "\n",
    "# Add empty cruising rate (Supports TK's Operational Cost Analysis)\n",
    "df = df.withColumn(\"daily_empty_rate\",\n",
    "    F.when(F.col(\"daily_moving_pings\") > 0,\n",
    "           F.col(\"daily_searching_fare_pings\") / F.col(\"daily_moving_pings\"))\n",
    "     .otherwise(0))\n",
    "\n",
    "# Add shift preference ratio (Supports TK's Shift Optimization)\n",
    "df = df.withColumn(\"daily_night_ratio\",\n",
    "    F.when(F.col(\"daily_ping_count\") > 0,\n",
    "           F.col(\"daily_night_shift_pings\") / F.col(\"daily_ping_count\"))\n",
    "     .otherwise(0))\n",
    "\n",
    "\n",
    "print(\"âœ“ Daily aggregated features created and joined (optimized)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39203aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5. Cleaning up...\n",
      "âœ“ Cleanup complete\n"
     ]
    }
   ],
   "source": [
    "# OPTIMIZATION 6: Drop temporary columns at the end\n",
    "print(\"\\n5. Cleaning up...\")\n",
    "df = df.drop(\"prev_lat\", \"prev_lon\", \"prev_for_hire\", \"normal_frequency\")\n",
    "\n",
    "print(\"âœ“ Cleanup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0017d75d",
   "metadata": {},
   "source": [
    "### Summary and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9eb3cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL DATA SUMMARY\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 18:27:32 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "25/11/24 18:27:33 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Final record count: 9,078,919\n",
      "âœ“ Number of columns: 73\n",
      "âœ“ Number of unique vehicles: 3,282\n",
      "\n",
      "--- Sample of Processed Data ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 18:27:35 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "25/11/24 18:27:36 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-------------------+-----+------------------+-----------+--------+----------------------+\n",
      "|vehicle_id                 |timestamp          |speed|area_type         |time_of_day|is_hired|daily_utilization_rate|\n",
      "+---------------------------+-------------------+-----+------------------+-----------+--------+----------------------+\n",
      "|+m8gZf8PGo8Y16q4nEYLlISr+PM|2023-01-04 22:43:47|55.0 |bmr_suburban_area |night      |1       |1.0                   |\n",
      "|+m8gZf8PGo8Y16q4nEYLlISr+PM|2023-01-04 22:45:40|53.0 |bmr_suburban_area |night      |1       |1.0                   |\n",
      "|+m8gZf8PGo8Y16q4nEYLlISr+PM|2023-01-04 22:54:40|87.0 |bmr_suburban_area |night      |1       |1.0                   |\n",
      "|+m8gZf8PGo8Y16q4nEYLlISr+PM|2023-01-04 23:39:58|70.0 |bmr_suburban_area |night      |1       |1.0                   |\n",
      "|+m8gZf8PGo8Y16q4nEYLlISr+PM|2023-01-05 00:03:58|58.0 |bangkok_outer_belt|night      |1       |0.4659090909090909    |\n",
      "|+m8gZf8PGo8Y16q4nEYLlISr+PM|2023-01-05 00:06:08|65.0 |bangkok_inner_ring|night      |1       |0.4659090909090909    |\n",
      "|+m8gZf8PGo8Y16q4nEYLlISr+PM|2023-01-05 00:16:08|45.0 |bangkok_inner_ring|night      |1       |0.4659090909090909    |\n",
      "|+m8gZf8PGo8Y16q4nEYLlISr+PM|2023-01-05 01:25:58|0.0  |bangkok_outer_belt|night      |1       |0.4659090909090909    |\n",
      "|+m8gZf8PGo8Y16q4nEYLlISr+PM|2023-01-05 02:10:58|39.0 |bangkok_inner_ring|night      |1       |0.4659090909090909    |\n",
      "|+m8gZf8PGo8Y16q4nEYLlISr+PM|2023-01-05 02:36:58|0.0  |bangkok_inner_ring|night      |0       |0.4659090909090909    |\n",
      "+---------------------------+-------------------+-----+------------------+-----------+--------+----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "================================================================================\n",
      "DATA PREPARATION COMPLETE - READY FOR ANALYTICS!\n",
      "================================================================================\n",
      "\n",
      "--- Save Options ---\n",
      "# Option 1: Partitioned Parquet (Recommended for distributed queries)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/11/24 18:27:36 WARN DAGScheduler: Broadcasting large task binary with size 3.3 MiB\n",
      "25/11/24 18:27:39 WARN DAGScheduler: Broadcasting large task binary with size 3.6 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processed dataframe ready in variable: df\n",
      "Use df.createOrReplaceTempView('taxi') for SQL queries\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# FINAL DATA SUMMARY\n",
    "# ==============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL DATA SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# NOTE: 'num_vehicles' is assumed to be defined elsewhere in the full script\n",
    "final_count = df.count()\n",
    "num_vehicles = df.select(\"vehicle_id\").distinct().count() # Recalculated for completeness\n",
    "print(f\"\\nâœ“ Final record count: {final_count:,}\")\n",
    "print(f\"âœ“ Number of columns: {len(df.columns)}\")\n",
    "print(f\"âœ“ Number of unique vehicles: {num_vehicles:,}\")\n",
    "\n",
    "print(\"\\n--- Sample of Processed Data ---\")\n",
    "df.select(\n",
    "    \"vehicle_id\", \n",
    "    \"timestamp\", \n",
    "    \"speed\", \n",
    "    \"area_type\", \n",
    "    \"time_of_day\", \n",
    "    \"is_hired\", \n",
    "    \"daily_utilization_rate\"\n",
    ").show(10, truncate=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA PREPARATION COMPLETE - READY FOR ANALYTICS!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "\n",
    "# Save options (choose one based on use case)\n",
    "print(\"\\n--- Save Options ---\")\n",
    "print(\"# Option 1: Partitioned Parquet (Recommended for distributed queries)\")\n",
    "df.write.mode(\"overwrite\").partitionBy(\"year\", \"month\").parquet(\"taxi_processed.parquet\")\n",
    "# print(\"\\n# Option 2: Single Parquet (Use for small datasets or after coalesce)\")\n",
    "# print('# df.coalesce(10).write.mode(\"overwrite\").parquet(\"output/taxi_processed.parquet\")')\n",
    "# print(\"\\n# Option 3: Delta Lake (Best for ACID compliance and updates)\")\n",
    "# print('# df.write.format(\"delta\").mode(\"overwrite\").save(\"output/taxi_processed_delta\")')\n",
    "\n",
    "print(\"\\nProcessed dataframe ready in variable: df\")\n",
    "print(\"Use df.createOrReplaceTempView('taxi') for SQL queries\")\n",
    "\n",
    "# Unpersist when done\n",
    "# df.unpersist()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
